{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash <(curl -sL https://gitlab.aicrowd.com/jyotish/pricing-game-notebook-scripts/raw/master/python/setup.sh)\n",
    "from aicrowd_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "class Config:\n",
    "    TRAINING_DATA_PATH = 'training.csv'\n",
    "    MODEL_OUTPUT_PATH = 'model.pkl'\n",
    "    AICROWD_API_KEY = 'YOUR API KEY'\n",
    "    ADDITIONAL_PACKAGES = [\n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'scikit-learn==' + sklearn.__version__, \n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%download_aicrowd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%track_imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import global_imports\n",
    "importlib.reload(global_imports)\n",
    "from global_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Config.TRAINING_DATA_PATH)\n",
    "X_train = df.drop(columns = ['claim_amount'])\n",
    "y_train = df['claim_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(n = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sample(n = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%aicrowd_include\n",
    "\n",
    "class Bag:\n",
    "    \"\"\"A bag of models, outputs of which are averaged.\"\"\"\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.means = None\n",
    "\n",
    "    def wrangle(self, df, means = None):\n",
    "        \"\"\"Prepare the predictors.\"\"\"\n",
    "        print(\"Wrangling data.\")\n",
    "        original_len = len(df)\n",
    "\n",
    "        # Use pre-existing means if available (i.e. on test set)\n",
    "        if means is None:\n",
    "            means = df[df.vh_weight > 0].mean()\n",
    "\n",
    "        # Replace 0 vehicle weight with mean\n",
    "        df.vh_weight = df.vh_weight.replace(0.0, means.vh_weight)\n",
    "\n",
    "        # Replace NaNs with column mean\n",
    "        nans = ['vh_age', 'vh_speed', 'vh_value', 'vh_weight']\n",
    "        df[nans] = df[nans].fillna(means[nans])\n",
    "\n",
    "        print('Done with replacing')\n",
    "        assert len(df) == original_len\n",
    "\n",
    "        # Join first year data\n",
    "        df = df.merge(df[df.year == 1.0][['id_policy', 'pol_no_claims_discount']].drop_duplicates(subset = 'id_policy'),\n",
    "                      on = 'id_policy', suffixes = ('', '_first'), how = 'left')\n",
    "\n",
    "        print(\"left join\")\n",
    "        print(\"original: {}, new: {}\".format(original_len, len(df)))\n",
    "        assert len(df) == original_len\n",
    "\n",
    "        # Change from beginning discount level\n",
    "        df['discount_base_change'] = df.pol_no_claims_discount - 0.631\n",
    "        # Yearly discount change over licence ownership\n",
    "        df['discount_yearly_change'] = df.discount_base_change / df.drv_age_lic1\n",
    "\n",
    "        # Discount change from policy beginning\n",
    "        df['discount_change'] = df.pol_no_claims_discount - df.pol_no_claims_discount_first\n",
    "        # Approx. no. of claims since first year\n",
    "        df['no_claims'] = np.maximum(np.zeros_like(df.year), np.ceil(df.discount_change / 0.2))\n",
    "\n",
    "        # Driver 1 and 2 combined info\n",
    "        df['drv_sex2'] = df.drv_sex2.replace('0', '')\n",
    "        df['drv_sexes'] = df.apply(lambda row: ''.join(sorted(row.drv_sex1 + row.drv_sex2)), axis=1)\n",
    "        df['drv_avg_age'] = np.mean(df[['drv_age1', 'drv_age2']], axis = 1)\n",
    "        df['drv_avg_lic'] = np.mean(df[['drv_age_lic1', 'drv_age_lic2']], axis = 1)\n",
    "\n",
    "        # Population density\n",
    "        df['pop_dens'] = df.population / df.town_surface_area\n",
    "\n",
    "        print('variable creation')\n",
    "        assert len(df) == original_len\n",
    "\n",
    "        # Drop unnecessary cols\n",
    "        df = df.drop(columns = ['id_policy', 'drv_drv2', 'drv_sex2', 'drv_age2', 'drv_age_lic2',\n",
    "                            'vh_make_model', 'pol_pay_freq', 'pol_no_claims_discount_first'])\n",
    "\n",
    "        print('drop cols')\n",
    "        assert len(df) == original_len\n",
    "\n",
    "\n",
    "        # One-hot encoding for categorical variables\n",
    "        cats = ['pol_coverage', 'pol_payd', 'pol_usage', 'drv_sex1', 'vh_fuel', 'vh_type',\n",
    "              'drv_sexes']\n",
    "        df = pd.get_dummies(df, prefix = cats, columns=cats)\n",
    "\n",
    "        assert len(df) == original_len\n",
    "        return df, means\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Fit all individual models.\"\"\"\n",
    "        x, means = self.wrangle(x)\n",
    "        self.means = means\n",
    "        print(\"Fitting models.\")\n",
    "        for model in self.models:\n",
    "            model.fit(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"Predict on all individual models and average their results.\"\"\"\n",
    "        preds = []\n",
    "        x, blah = self.wrangle(x, self.means)\n",
    "        for model in self.models:\n",
    "            preds.append(model.predict(x))\n",
    "        return np.mean(preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_raw, y_raw):\n",
    "    \"\"\"Model training function: given training data (X_raw, y_raw), train this pricing model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
    "        Each row is a different contract. This data has not been processed.\n",
    "    y_raw : a Numpy array, with the value of the claims, in the same order as contracts in X_raw.\n",
    "        A one dimensional array, with values either 0 (most entries) or >0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    self: this instance of the fitted model. This can be anything, as long as it is compatible\n",
    "        with your prediction methods.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    models = [\n",
    "              RandomForestRegressor(n_estimators = 100,\n",
    "                                    max_depth = 8,\n",
    "                                    max_features = 'log2',\n",
    "                                    min_samples_split = 200,\n",
    "                                    random_state = 2021),\n",
    "        \n",
    "              GradientBoostingRegressor(n_estimators = 65,\n",
    "                                        learning_rate = 0.5,\n",
    "                                        max_depth = 1,\n",
    "                                        loss = 'ls')\n",
    "    ]\n",
    "\n",
    "    bag = Bag(models)\n",
    "    bag.fit(X_raw, y_raw)\n",
    "\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = fit_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_path):  # some models such xgboost models or keras models don't pickle very reliably. Please use the package provided saving functions instead. \n",
    "    with open(model_path, 'wb') as target_file:\n",
    "        pickle.dump(trained_model, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(Config.MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path): # some models such xgboost models or keras models don't pickle very reliably. Please use the package provided saving functions instead. \n",
    "    with open(model_path, 'rb') as target:\n",
    "        return pickle.load(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = load_model(Config.MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_expected_claim(model, X_raw):\n",
    "    \"\"\"Model prediction function: predicts the expected claim based on the pricing model.\n",
    "\n",
    "    This functions estimates the expected claim made by a contract (typically, as the product\n",
    "    of the probability of having a claim multiplied by the expected cost of a claim if it occurs),\n",
    "    for each contract in the dataset X_raw.\n",
    "\n",
    "    This is the function used in the RMSE leaderboard, and hence the output should be as close\n",
    "    as possible to the expected cost of a contract.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: a Python object that describes your model. This can be anything, as long\n",
    "        as it is consistent with what `fit` outpurs.\n",
    "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
    "        Each row is a different contract. This data has not been processed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    avg_claims: a one-dimensional Numpy array of the same length as X_raw, with one\n",
    "        expected claim per contract (in same order). These expected claims must be POSITIVE (>0).\n",
    "    \"\"\"\n",
    "\n",
    "    preds = model.predict(X_raw)\n",
    "    preds[preds < 0] = 0\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_expected_claim(trained_model, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_premium(model, X_raw):\n",
    "    \"\"\"Model prediction function: predicts premiums based on the pricing model.\n",
    "\n",
    "    This function outputs the prices that will be offered to the contracts in X_raw.\n",
    "    premium will typically depend on the average claim predicted in \n",
    "    predict_average_claim, and will add some pricing strategy on top.\n",
    "\n",
    "    This is the function used in the average profit leaderboard. Prices output here will\n",
    "    be used in competition with other models, so feel free to use a pricing strategy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: a Python object that describes your model. This can be anything, as long\n",
    "        as it is consistent with what `fit` outpurs.\n",
    "    X_raw : Pandas dataframe, with the columns described in the data dictionary.\n",
    "        Each row is a different contract. This data has not been processed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prices: a one-dimensional Numpy array of the same length as X_raw, with one\n",
    "        price per contract (in same order). These prices must be POSITIVE (>0).\n",
    "    \"\"\"\n",
    "    # Minimum price to offer\n",
    "    base = 110\n",
    "    # Scale predicted claims\n",
    "    risk = 1.5\n",
    "\n",
    "    claims = predict_expected_claim(model, X_raw)\n",
    "\n",
    "    prices = claims * risk\n",
    "    prices[prices < base] = base\n",
    "\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = predict_premium(trained_model, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Income:', prices.sum())\n",
    "print('Losses:', y_train.sum())\n",
    "\n",
    "if prices.sum() < y_train.sum():\n",
    "    print('Your model loses money on the training data! It does not satisfy market rule 1: Non-negative training profit.')\n",
    "    print('This model will be disqualified from the weekly profit leaderboard, but can be submitted for educational purposes to the RMSE leaderboard.')\n",
    "else:\n",
    "    print('Your model passes the non-negative training profit test!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aicrowd_submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
